<!DOCTYPE html>
<html>

<head>
	<link rel="stylesheet" href="../basestyle.css" type="text/css">
	<meta charset="UTF-8"/>
	<meta author='Karyn Nakamura'>
	<title>Surface Tension</title>
	<meta name="viewport" content="initial-scale=1" /> 
  	<link rel="image_src" href="../folder.png"/>
	<meta property="og:image" content = "../folder.png" />
	<link rel="icon" href="../folder.png">
	<script src="https://d3js.org/d3.v5.min.js"></script>
</head>

<body>
<p><img src="https://www.dropbox.com/scl/fi/sf2c03wc8sp2vaom8twu9/s_Lara-Hughes-Install-2.jpg?rlkey=a97qmz9xx7yq1vznqvtu2ooqx&st=rwbx80af&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/eks536xnicogw5or49dab/s_J5A0282.jpg?rlkey=244qbpndnrrc43ps63ybt4ydu&st=ocdyqa3c&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/u946i687qesx7yjnclzuz/s_ST_-28_2.2.jpg?rlkey=1t2pfz95atw5r7f5ohjvad2jo&st=9ct4pfvi&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/cc2l9vbkw0n1ggwnv91tf/s_J5A9696.jpg?rlkey=h4n3xxl6xs778rfhp31wle4k6&st=2chs52g3&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/u1jlkxnwpg95ve1vbnho8/s_Lara-Hughes-Install.jpg?rlkey=21hufiuot3n433rh5qzjgfwo9&st=yp06zg7i&&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/8s45cene0i0of3daeehod/s_ST_-22.jpg?rlkey=uv3ky2jaooirr21qr70pe6kw9&st=91kr1v33&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/bwqz4pjmcjre23hdewyz1/s_ST_-17_2.jpg?rlkey=5ww98rwhprkvfkn8m1yzfzxjl&st=exlj5vm6&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/lbhygyw17ri9yne9dkici/s_ST_-01.jpg?rlkey=7b8z2o70zf2f52xdm8cxrjn9r&st=7iexc7ke&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/5jas8vz0f6wzwaz898gk9/s_J5A0273.jpg?rlkey=7cey46362x2br4p4g4aw5om5b&st=cawh0h8l&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/3pcabwumj67vuofyy5pq2/s_ST_-29.jpg?rlkey=wqqlu095poe124nja9b4t4jhl&st=8sjlgmc1&raw=1" alt=""></p>
<p><img src="https://www.dropbox.com/scl/fi/gbyje5tbvx23a187fr2eb/transformation.001.jpeg?rlkey=dev994g8j9jqvi0r7x6fhk068&st=pjzg7kp1&raw=1" alt=""></p>

<iframe style = "max-width: 100vw; width: 100vw; height: 100vh; position: relative; border-width: 0px;" src = "https://www.youtube.com/watch_popup?v=OZe_Fi722TY&t=5s&vq=1440"></iframe>

<div class = "mask"></div>

<div class = "title">
	<h1>Surface Tension</h1>
	<h2>March 2025</h2>
	<h3>A composition of video, a slide projector, a drone, security cameras, and lasers featuring an absurd microscopic cinema in which individual neuron cells perform as actors trying to form a “THOUGHT” using the technology of optical tweezers.</h3>
	<button id="text" class="button text">INFO</button>
</div>

<div class = "footer">
<a class = "back" href = "../root.html">back</a>

<div class = "scroll">

	<p><a href="https://www.showstudio.com/projects/surface-tension?gallery=false&look=1">FULL PROJECT ARCHIVE</a></p>
	<br> 
	<p>The installation was designed and constructed during a two-week residency in <a href="https://www.showstudio.com/">SHOWStudio Gallery</a></p>
	<br> 

	<p><a href="https://www.showstudio.com/projects/surface-tension/press-release-surface-tension">PRESS RELEASE</a></p>
	<p><a href="https://www.showstudio.com/projects/surface-tension/interview-surface-tension">INTERVIEW + WALKTHROUGH</a></p>
	<p><a href="https://www.showstudio.com/projects/surface-tension/tech-101-what-does-freedom-mean-in-a-technologically-driven-world">TALK ON TECHNOLOGY & FREEDOM with Jack Self</a></p>
				
	<br> 
	<h2>ABOUT: </h2>
	<p>How do we measure and see worlds we cannot see with our own eyes? When we rely on technology as an intermediary for vision, how do we validate its interpretations? Surface Tension examines the power of visual media in shaping our realities, probing the tensions between visibility and authority in the media through which we produce and share knowledge. </p>	
	<br>
	<p>At its core lies the installation’s kernel of truth - raw footage from a microscope capturing a meticulous process of animating individual neurons (cellular matter of human brains) through physical manipulation. Using optical tweezers, neurons are lifted and orchestrated into movement by the energy of a light beam, drifting in and out of formations that attempt to spell the word "THOUGHT."</p>
	<br>
	<p>Throughout the part live-generated, part pre-sequenced 15 minute experience, the microscopic footage undergoes visual transformations through computational processes from color inversions to textures generated with diffusion models. These textures cycle through - each one concealing and revealing different facets, filtering and molding our perception of the neurons. Images at various stages in the technological reconstruction of the absurd reality morph in and out, slide over and under each other, wearing the traces of their own making like a skin.</p>
	<br>
	<p>The final multi-channel video piece unfolds as a series of vignettes, capturing moments of optically animated neurons (which have been sped up around 40 times). These are spread across five screens and a wall of projection. Over the course of the video, the raw bright-field microscope footage undergoes multiple transformations, processed through computational techniques including body-like textures generated using diffusion models. Computational neural networks - modeled after an abstraction of the brain - are used to reimagine and embellish the image of its own material form.</p>
	<br>
	<p>As an additional channel, a slide projector modified into a microscope that projects the actual specimens on the slides used under the optical tweezers, creating a meta-animation of its own process. Finally, a choreographed drone weaves through the space capturing a single, curated perspective of the work. This is broadcasted on a TV in the front gallery, where a large mirror sculpture obscures full view of the main space. Like the microscope that lets us peek into microscopic world, the drone's eye becomes the only way to see inside the gallery - another mediated gaze, filtering reality through a particular perspective, shaping what can be seen and what remains hidden.</p>

	<br> 
	<h2>TECHNICAL INFO: </h2>
	<p>Custom Stable Diffusion pipelines were developed to utilize depth maps and edge-detected images of the original microscope footage to guide the generation of various skin-like textures. In typical SD1.5 workflows, image generation follows a 30-step sampling process, progressively refining noise into a cohesive image. In addition to simply generating images, the process was intercepted at very early stages (3–10 steps) to extract half-formed latents which were converted directly to RGB images, bypassing the usual decoding process. </p>
	<br>
	<p>Premature, half-baked AI generations offer a raw glimpse into the otherwise hidden mechanics of image generation. These are woven into the video, layering the neurons' movements with their forms imagined by computational neural networks along with the visual residue of their constructed image.</p>
	<br> 
	<h2>ACKNOWLEDGEMENTS:</h2>
	<p>Curator and Exhibition Sponsor - Nick Knight and SHOWStudio</p>
	<p>Gallery Assistant - Hollie Hunsdale</p>
	<p>Bioengineering Advisor - Yitong Tseo (MIT)</p>
	<p>Optical Tweezers Specialists - Professor David Grier (NYU), Jatin Abacousnac (NYU)</p>
	<p>Exhibition and Editorial support - SHOWStudio Team</p>
	<p>Set Construction - Andy Tomlinson (Liberte Productions)</p>
	<p>Grant Support - Steve Jobs Archive</p>
	<p>Installation Photographer - Lara Hughes</p>

	<br><br>

</div>

</div>
</body>
<script type="text/javascript" src="../base.js"></script>